{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "This is a companion notebook for the book [Deep Learning with Python, Second Edition](https://www.manning.com/books/deep-learning-with-python-second-edition?a_aid=keras&a_bid=76564dff). For readability, it only contains runnable code blocks and section titles, and omits everything else in the book: text paragraphs, figures, and pseudocode.\n",
    "\n",
    "**If you want to be able to follow what's going on, I recommend reading the notebook side by side with your copy of the book.**\n",
    "\n",
    "This notebook was generated for TensorFlow 2.6."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "# Working with Keras: A deep dive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## A spectrum of workflows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Different ways to build Keras models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### The Sequential model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**The `Sequential` class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(64, activation=\"relu\"),\n",
    "    layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Incrementally building a Sequential model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(layers.Dense(64, activation=\"relu\"))\n",
    "model.add(layers.Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Calling a model for the first time to build it**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'dense_2/kernel:0' shape=(3, 64) dtype=float32, numpy=\n",
       " array([[ 0.04252228, -0.11547153,  0.1642617 ,  0.28125447,  0.02076381,\n",
       "          0.17891738, -0.16295283, -0.00758916, -0.2852762 ,  0.10708994,\n",
       "          0.28637308, -0.0921863 ,  0.01066029, -0.11093441,  0.05983886,\n",
       "         -0.19443351,  0.09910536, -0.1236735 ,  0.05995816, -0.08250974,\n",
       "          0.02947706,  0.01290333, -0.23580667,  0.28169715, -0.19227725,\n",
       "         -0.24683207,  0.27817732, -0.10661118, -0.17372087, -0.28067565,\n",
       "         -0.01185054, -0.24744743, -0.27474952,  0.02532271,  0.01627401,\n",
       "          0.15783721,  0.2833252 , -0.18335433,  0.23917943,  0.17800313,\n",
       "         -0.27302834,  0.24498719,  0.23414832, -0.24735376,  0.29349053,\n",
       "         -0.24153666, -0.09795652, -0.06861997, -0.1538409 , -0.21554899,\n",
       "          0.04080167, -0.09380418, -0.20630345,  0.10175833,  0.22828776,\n",
       "         -0.02749744, -0.26408958,  0.06533855, -0.2921559 , -0.00757831,\n",
       "          0.04400632,  0.16730559, -0.11223307,  0.10196546],\n",
       "        [-0.08302094, -0.00108105, -0.14433841,  0.28455347, -0.1327222 ,\n",
       "          0.04973829,  0.07212111, -0.1622332 ,  0.13148966,  0.24616367,\n",
       "         -0.22407202, -0.04487076, -0.27657083,  0.21226794,  0.28964978,\n",
       "          0.2704779 ,  0.01835257,  0.06369671,  0.2521782 , -0.14298931,\n",
       "         -0.17218447, -0.03177437, -0.03353286,  0.24402714, -0.23278162,\n",
       "         -0.12274989,  0.10119849, -0.02391645, -0.16138853,  0.29391074,\n",
       "          0.06935257, -0.05154203,  0.28210652,  0.10534042,  0.20274484,\n",
       "         -0.02439997, -0.03160655,  0.29486638,  0.21226782, -0.02702078,\n",
       "         -0.22487006,  0.03599849, -0.2724306 , -0.03015441, -0.28693426,\n",
       "         -0.00701609, -0.07606742,  0.24365526,  0.18795395,  0.05384377,\n",
       "         -0.29288912,  0.26132035, -0.10991992,  0.03868002, -0.18955734,\n",
       "          0.17769492,  0.25883853, -0.04809251, -0.02509916, -0.16867596,\n",
       "          0.0920195 , -0.28390133,  0.09267744,  0.24050242],\n",
       "        [-0.20763735, -0.11668101, -0.11302175,  0.27182877, -0.00324872,\n",
       "          0.08235618,  0.10725152,  0.03796524,  0.19825488, -0.19695522,\n",
       "          0.28512788, -0.23625118, -0.2315361 ,  0.21846867,  0.28696758,\n",
       "         -0.0153245 ,  0.2134878 , -0.14448039,  0.16062838,  0.24906534,\n",
       "         -0.11562358, -0.20291087, -0.17853132,  0.16111171,  0.02718237,\n",
       "          0.25524306, -0.08333658, -0.12329356,  0.07706049, -0.07886559,\n",
       "         -0.17207551,  0.20208234,  0.26809287,  0.18708238,  0.27342898,\n",
       "         -0.28259346, -0.2397798 , -0.22323191, -0.15164483,  0.29695582,\n",
       "         -0.1547062 ,  0.11786774,  0.21187377,  0.11058766, -0.09601781,\n",
       "         -0.22770098,  0.14436117, -0.20647398, -0.2919656 , -0.06307904,\n",
       "         -0.09009981, -0.08937706,  0.23860323, -0.27392974,  0.12987167,\n",
       "         -0.27370378,  0.17054719,  0.20520735, -0.18003747, -0.26629174,\n",
       "          0.18095627, -0.2934429 ,  0.00751746,  0.21959019]],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'dense_2/bias:0' shape=(64,) dtype=float32, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n",
       " <tf.Variable 'dense_3/kernel:0' shape=(64, 10) dtype=float32, numpy=\n",
       " array([[-2.27485687e-01,  7.06191063e-02, -2.35474586e-01,\n",
       "         -7.86993206e-02,  1.66984707e-01, -1.62734240e-01,\n",
       "         -8.12605023e-02,  1.87699020e-01, -2.80428559e-01,\n",
       "          2.74038106e-01],\n",
       "        [-1.36746094e-01,  2.06723899e-01, -9.41687971e-02,\n",
       "         -1.17468044e-01,  1.35491848e-01,  1.71982825e-01,\n",
       "          4.74092364e-02,  2.07046032e-01,  2.70791501e-01,\n",
       "          1.19129092e-01],\n",
       "        [ 2.72089630e-01, -2.37045586e-02, -1.40356913e-01,\n",
       "          1.06468111e-01, -8.85486007e-02,  2.35644788e-01,\n",
       "         -1.86415702e-01, -2.17852831e-01,  1.16572320e-01,\n",
       "          6.49460852e-02],\n",
       "        [-2.66758889e-01, -2.64453322e-01,  4.47932780e-02,\n",
       "          2.44753152e-01, -9.01943594e-02, -2.73067683e-01,\n",
       "         -2.38830894e-01,  2.02637404e-01, -8.71320963e-02,\n",
       "         -2.79837310e-01],\n",
       "        [-1.85811222e-01,  2.55993694e-01, -2.21645042e-01,\n",
       "          1.23690426e-01,  1.98660374e-01,  2.67024010e-01,\n",
       "          1.59434021e-01,  5.91746867e-02,  2.15004414e-01,\n",
       "         -4.47943658e-02],\n",
       "        [ 2.01650500e-01,  2.46394128e-01, -5.32633215e-02,\n",
       "         -1.35066450e-01, -1.44457206e-01, -1.36483639e-01,\n",
       "         -1.13856792e-03, -2.26626277e-01, -1.97220936e-01,\n",
       "          1.21644855e-01],\n",
       "        [-2.12800324e-01,  8.72544348e-02, -1.35616630e-01,\n",
       "          2.40442723e-01,  1.27217472e-01, -8.48759264e-02,\n",
       "          1.23816490e-01, -1.61885768e-01, -9.80179012e-02,\n",
       "          5.12352586e-03],\n",
       "        [ 1.41458541e-01,  1.82387114e-01,  1.98981583e-01,\n",
       "          2.48042345e-02, -1.49663210e-01, -7.26328194e-02,\n",
       "          1.04004562e-01,  1.25471890e-01,  8.26829672e-02,\n",
       "         -1.06458887e-01],\n",
       "        [ 1.75436974e-01, -1.34074688e-02,  1.54660136e-01,\n",
       "          7.27465749e-03,  2.30378777e-01, -2.40954801e-01,\n",
       "         -9.13172960e-04,  3.42943668e-02, -4.02857065e-02,\n",
       "         -1.17882237e-01],\n",
       "        [ 1.91197127e-01, -1.75756857e-01,  5.20451069e-02,\n",
       "         -1.32147640e-01,  1.52090102e-01,  1.69569105e-01,\n",
       "         -1.92939937e-02,  1.69212878e-01,  2.41572887e-01,\n",
       "          7.17013776e-02],\n",
       "        [ 1.95809007e-02,  2.10429370e-01,  1.34906292e-01,\n",
       "         -2.59484977e-01,  2.80304462e-01,  1.57521158e-01,\n",
       "         -1.81709170e-01,  1.46074682e-01,  1.98328763e-01,\n",
       "          5.21124005e-02],\n",
       "        [-3.31461728e-02, -9.66039747e-02, -9.58248824e-02,\n",
       "         -2.05281064e-01, -1.93112493e-02, -2.64358461e-01,\n",
       "         -1.83149874e-02,  8.20031464e-02,  2.16248900e-01,\n",
       "          2.46126205e-01],\n",
       "        [-2.46489316e-01,  2.71137208e-01, -3.42244506e-02,\n",
       "         -1.65858090e-01, -1.17458269e-01, -4.58175242e-02,\n",
       "         -1.99274853e-01,  2.47475952e-01,  2.10269153e-01,\n",
       "         -1.10012472e-01],\n",
       "        [ 5.14638424e-02, -1.64125562e-01, -2.72765636e-01,\n",
       "         -2.74333358e-03,  2.41227835e-01,  6.31867349e-02,\n",
       "         -2.04376578e-02, -1.11330062e-01,  1.45530939e-01,\n",
       "         -2.24848926e-01],\n",
       "        [-2.44342327e-01,  1.40176117e-01,  3.05977464e-03,\n",
       "         -2.81551570e-01, -2.12862372e-01, -3.89517546e-02,\n",
       "         -1.98079124e-01, -1.41003013e-01, -1.33965835e-01,\n",
       "         -1.27786309e-01],\n",
       "        [-1.84970826e-01,  4.12457287e-02,  1.26896411e-01,\n",
       "         -3.96333635e-02, -4.67849374e-02, -1.04350314e-01,\n",
       "         -4.69061136e-02,  2.11849958e-01, -2.26550579e-01,\n",
       "         -3.28816772e-02],\n",
       "        [-1.05814546e-01,  1.42123997e-01,  2.01913506e-01,\n",
       "          2.65221149e-01,  2.75627941e-01, -2.25271404e-01,\n",
       "         -7.44626373e-02, -1.28059015e-01,  2.16529876e-01,\n",
       "         -2.76172787e-01],\n",
       "        [-2.93198526e-02, -1.58501416e-01,  2.18524188e-01,\n",
       "          1.57491833e-01,  1.73319310e-01,  1.01979434e-01,\n",
       "         -2.18955874e-02, -2.21291482e-01, -9.17382240e-02,\n",
       "         -2.17090577e-01],\n",
       "        [ 4.96758521e-02,  1.47424906e-01,  1.64490789e-01,\n",
       "          1.62547201e-01, -1.38600349e-01, -2.33763114e-01,\n",
       "         -2.14289814e-01,  4.76777554e-04, -7.86093026e-02,\n",
       "          6.45893216e-02],\n",
       "        [-1.57969102e-01,  2.47069091e-01,  2.83404797e-01,\n",
       "          5.77114820e-02, -1.01863205e-01, -6.21640682e-03,\n",
       "          2.04962134e-01, -7.85767138e-02, -1.48596480e-01,\n",
       "          1.92197204e-01],\n",
       "        [ 1.71623230e-01,  5.17252386e-02,  1.69787705e-01,\n",
       "         -2.74177879e-01, -1.20401978e-02, -1.21646762e-01,\n",
       "         -2.55898952e-01,  2.77657777e-01, -3.23131680e-03,\n",
       "          2.17194855e-02],\n",
       "        [-1.21241525e-01,  1.33780420e-01,  1.43096775e-01,\n",
       "         -1.82414323e-01,  2.28788346e-01, -3.76279205e-02,\n",
       "         -1.91827834e-01, -4.47718203e-02,  2.30336875e-01,\n",
       "          1.63385421e-01],\n",
       "        [ 1.92155331e-01, -1.99783072e-01,  2.05864787e-01,\n",
       "          2.51619607e-01,  1.35783643e-01,  1.46098733e-02,\n",
       "          6.99754357e-02,  2.56560355e-01,  1.05162144e-01,\n",
       "          2.23423392e-01],\n",
       "        [ 9.85024273e-02, -2.57950008e-01,  3.27388942e-02,\n",
       "          1.56738013e-01,  1.14317596e-01,  1.35771483e-01,\n",
       "         -8.67033005e-02, -1.35396734e-01, -1.34587571e-01,\n",
       "         -2.23314703e-01],\n",
       "        [ 3.21266651e-02, -1.22513562e-01,  1.51569009e-01,\n",
       "          6.45794868e-02, -2.15845495e-01, -3.23554575e-02,\n",
       "          2.67214686e-01, -1.49451062e-01, -2.26896107e-02,\n",
       "         -1.07782453e-01],\n",
       "        [ 2.14650035e-01, -5.75482845e-03,  1.78140312e-01,\n",
       "          2.15842277e-01, -1.26011550e-01,  4.85959351e-02,\n",
       "         -1.54872611e-01,  1.68975413e-01,  1.95052505e-01,\n",
       "          1.75404996e-01],\n",
       "        [-1.98352441e-01, -2.83845067e-01,  2.81396240e-01,\n",
       "          1.59714937e-01,  1.20634198e-01,  2.12392211e-02,\n",
       "         -8.37542713e-02, -1.74272463e-01,  1.49068385e-01,\n",
       "         -1.16293088e-01],\n",
       "        [-8.58677924e-02,  2.26747543e-01,  9.90307331e-02,\n",
       "         -1.18890390e-01, -2.48681054e-01,  3.08028460e-02,\n",
       "         -4.42524701e-02,  1.34998500e-01, -3.05887163e-02,\n",
       "          2.76092082e-01],\n",
       "        [ 2.01642483e-01,  4.93404269e-03,  1.07308775e-01,\n",
       "          2.50594020e-02,  9.66312587e-02, -9.33017731e-02,\n",
       "         -1.67134061e-01, -6.63772225e-03,  4.51993942e-02,\n",
       "          1.10311985e-01],\n",
       "        [-1.63304299e-01, -3.68119627e-02,  1.91444248e-01,\n",
       "          9.49406922e-02, -1.10773236e-01,  1.45942360e-01,\n",
       "         -1.38010740e-01, -1.33195519e-02, -2.43140280e-01,\n",
       "          1.69369787e-01],\n",
       "        [ 1.47793889e-01, -1.43325701e-01, -8.79118592e-02,\n",
       "         -2.42526978e-01,  2.54172951e-01, -9.63286757e-02,\n",
       "          2.25803405e-01, -2.13415533e-01, -3.72055173e-02,\n",
       "         -1.22722983e-02],\n",
       "        [-1.03116706e-01, -9.79536027e-02,  2.45337695e-01,\n",
       "         -8.00544471e-02,  1.74961388e-01, -2.37747252e-01,\n",
       "          2.27566928e-01,  8.53023529e-02,  4.56708670e-02,\n",
       "          1.38556629e-01],\n",
       "        [ 9.64715779e-02, -1.92689613e-01,  2.51400799e-01,\n",
       "         -1.02452755e-01,  2.39477187e-01, -2.82869041e-01,\n",
       "          1.09412253e-01, -2.86373198e-02, -2.54294038e-01,\n",
       "         -5.86007535e-02],\n",
       "        [ 1.68527424e-01,  2.01917589e-02,  2.23857671e-01,\n",
       "         -7.59145766e-02, -1.55025303e-01, -2.31048495e-01,\n",
       "          1.55900240e-01, -5.71293980e-02,  1.10599637e-01,\n",
       "          1.37038827e-01],\n",
       "        [-2.14505017e-01, -2.10265815e-01,  1.05716109e-01,\n",
       "          2.05351412e-01, -2.83885330e-01, -1.45596996e-01,\n",
       "         -1.73336059e-01, -1.77635550e-01, -1.86406076e-01,\n",
       "          2.02828228e-01],\n",
       "        [ 9.42499042e-02,  1.58338428e-01, -1.09538406e-01,\n",
       "          1.44645274e-01, -2.80389190e-03,  8.62873495e-02,\n",
       "         -1.02735177e-01,  2.03941286e-01,  2.58863240e-01,\n",
       "          2.84426421e-01],\n",
       "        [-8.90176445e-02,  1.95451379e-02,  4.42770422e-02,\n",
       "          2.16395110e-01, -2.77596027e-01,  4.18363810e-02,\n",
       "          1.83015496e-01,  7.99981058e-02, -1.73334643e-01,\n",
       "          1.12807125e-01],\n",
       "        [ 7.21161067e-02,  1.22954309e-01, -2.47639358e-01,\n",
       "          2.48147547e-02, -2.37060487e-01, -8.45498592e-02,\n",
       "         -1.58378482e-02, -5.75896800e-02, -1.65849462e-01,\n",
       "          2.01600730e-01],\n",
       "        [ 1.45233601e-01,  1.96490586e-02,  3.63826752e-04,\n",
       "          2.28996664e-01,  7.08599687e-02, -2.39764452e-02,\n",
       "         -1.86168388e-01, -9.96741205e-02, -3.37245762e-02,\n",
       "         -9.94555801e-02],\n",
       "        [ 1.73555613e-01, -2.42425755e-01,  1.30175054e-01,\n",
       "         -2.02576816e-02,  2.64693886e-01, -1.39420047e-01,\n",
       "          2.04778969e-01,  1.56847179e-01,  2.75880307e-01,\n",
       "          1.79146826e-01],\n",
       "        [-2.46425375e-01,  6.36872053e-02, -2.46962637e-01,\n",
       "          7.40464032e-02, -2.69820750e-01, -1.24766871e-01,\n",
       "          7.77396262e-02,  1.87452227e-01,  1.59436196e-01,\n",
       "         -8.82938802e-02],\n",
       "        [ 9.78028178e-02,  2.53409654e-01, -2.73683995e-01,\n",
       "          7.81584382e-02,  2.30073929e-05,  1.71293080e-01,\n",
       "          2.37514466e-01, -1.85196355e-01, -2.31738314e-01,\n",
       "          7.44745731e-02],\n",
       "        [ 1.09711796e-01,  1.54256731e-01,  1.35511160e-04,\n",
       "         -1.20148301e-01,  3.71500552e-02, -2.41969466e-01,\n",
       "         -1.08549729e-01, -1.58402711e-01,  9.13759768e-02,\n",
       "          1.96971655e-01],\n",
       "        [ 1.83834642e-01, -1.40545651e-01,  2.70527154e-01,\n",
       "          1.93945140e-01, -1.95297569e-01,  1.69497430e-01,\n",
       "          2.63586491e-01,  2.22983390e-01,  2.10352302e-01,\n",
       "         -2.60273814e-02],\n",
       "        [ 7.40146339e-02, -1.27467766e-01,  6.23140037e-02,\n",
       "          1.96042031e-01,  7.22202659e-03, -6.63880408e-02,\n",
       "          1.95942223e-02,  1.92017108e-01, -1.46721512e-01,\n",
       "          1.80453151e-01],\n",
       "        [-2.09728479e-01,  9.64297652e-02,  1.78803235e-01,\n",
       "         -1.77757278e-01,  4.23673987e-02, -4.73880023e-02,\n",
       "         -2.37166122e-01,  1.13052130e-02, -7.79267997e-02,\n",
       "          2.34921068e-01],\n",
       "        [ 4.28718925e-02,  1.57706767e-01,  2.02065825e-01,\n",
       "         -2.34042883e-01, -7.44512677e-03, -1.83312029e-01,\n",
       "          2.31646389e-01, -1.27867222e-01,  1.10638142e-03,\n",
       "          2.44335562e-01],\n",
       "        [ 1.72092944e-01, -1.47854924e-01,  2.94318795e-03,\n",
       "         -7.44847655e-02,  5.68556786e-02, -6.72273487e-02,\n",
       "          6.72380924e-02, -2.08999828e-01, -1.05658412e-01,\n",
       "         -1.01486355e-01],\n",
       "        [ 2.16541678e-01, -1.91829801e-01,  1.03739858e-01,\n",
       "          2.48050243e-01,  7.57719278e-02,  8.68666470e-02,\n",
       "          2.64569312e-01, -2.52782911e-01, -4.04194593e-02,\n",
       "          1.42074317e-01],\n",
       "        [-1.39729351e-01,  2.11222857e-01,  2.05665320e-01,\n",
       "         -2.81344593e-01, -2.64020056e-01, -1.27721727e-02,\n",
       "          2.65219659e-01, -9.43691283e-02, -9.40573812e-02,\n",
       "         -8.07019770e-02],\n",
       "        [-1.46282002e-01, -5.72538376e-02, -8.89993161e-02,\n",
       "         -1.24806464e-02, -8.31109583e-02, -1.43369690e-01,\n",
       "         -8.62952173e-02, -8.02535713e-02,  3.89064848e-02,\n",
       "          1.72094911e-01],\n",
       "        [ 1.21936172e-01,  4.00768220e-02,  1.43278509e-01,\n",
       "          1.12079501e-01, -1.09221429e-01, -2.50487030e-01,\n",
       "          2.68479586e-02, -2.58276761e-01, -1.61876082e-02,\n",
       "          1.89966917e-01],\n",
       "        [-6.26518279e-02, -7.18028098e-02, -7.38275945e-02,\n",
       "          2.79420048e-01,  4.65847254e-02,  2.76152998e-01,\n",
       "         -1.05087325e-01, -1.21731818e-01,  5.81023097e-02,\n",
       "          8.17273855e-02],\n",
       "        [ 1.97354406e-01, -1.76924139e-01,  6.86661899e-02,\n",
       "          2.29259998e-01,  1.76543087e-01, -1.31958291e-01,\n",
       "          5.38377166e-02, -9.62744355e-02,  1.71097487e-01,\n",
       "          1.02808148e-01],\n",
       "        [-7.35068917e-02,  1.60106450e-01, -2.82644629e-02,\n",
       "          1.92180723e-01, -9.54098701e-02,  1.39670342e-01,\n",
       "          1.85511976e-01, -1.05497539e-02, -1.85630292e-01,\n",
       "         -1.53076947e-02],\n",
       "        [ 2.43389457e-01,  4.43346798e-02,  9.13503766e-02,\n",
       "         -1.91376984e-01, -1.80991381e-01, -3.98114324e-02,\n",
       "         -1.89609408e-01, -1.29362956e-01,  4.83926833e-02,\n",
       "          7.51599967e-02],\n",
       "        [ 1.67046905e-01, -1.06052503e-01,  2.65908509e-01,\n",
       "          2.80942619e-02,  4.60602343e-02,  1.73834294e-01,\n",
       "          1.43472612e-01, -3.94214243e-02,  8.58193040e-02,\n",
       "         -1.63888276e-01],\n",
       "        [-2.45487422e-01, -1.14097565e-01,  1.26289159e-01,\n",
       "         -4.25523221e-02,  1.86835408e-01, -3.72744203e-02,\n",
       "         -1.84318691e-01, -2.47647434e-01,  2.83973008e-01,\n",
       "          1.70846045e-01],\n",
       "        [-1.58791170e-01,  2.18621790e-02, -2.10390598e-01,\n",
       "         -1.12721026e-02,  5.37553728e-02,  9.33756530e-02,\n",
       "          2.44125277e-01,  6.55125380e-02, -1.60943061e-01,\n",
       "          8.15503895e-02],\n",
       "        [-7.11677074e-02,  2.50927716e-01, -8.10001493e-02,\n",
       "         -2.35707387e-01,  2.84380227e-01,  3.43925953e-02,\n",
       "          1.44975126e-01,  1.82719231e-01, -6.99736029e-02,\n",
       "          2.04098642e-01],\n",
       "        [-2.27830008e-01,  2.71165967e-02,  1.61197156e-01,\n",
       "          2.70063847e-01, -2.04612151e-01,  2.66840160e-02,\n",
       "         -2.28990614e-02, -2.52989352e-01, -2.79905736e-01,\n",
       "         -2.31689304e-01],\n",
       "        [ 1.93016827e-02,  1.93630010e-01,  2.67877549e-01,\n",
       "         -8.23244452e-03,  2.22753584e-02,  3.85135412e-03,\n",
       "          9.58882272e-02, -1.86095893e-01, -2.57029086e-01,\n",
       "          1.50151759e-01],\n",
       "        [ 1.16714954e-01, -2.50891030e-01, -4.53226119e-02,\n",
       "         -4.48537618e-02, -1.58183843e-01,  9.44595039e-02,\n",
       "         -2.53347158e-02,  2.82324761e-01,  1.51531696e-02,\n",
       "          9.13266242e-02],\n",
       "        [-5.54215759e-02, -6.94270283e-02, -1.81751937e-01,\n",
       "          1.96931720e-01, -2.67881036e-01,  4.10922468e-02,\n",
       "          2.69118160e-01, -2.81575203e-01,  1.37184799e-01,\n",
       "         -2.77970701e-01]], dtype=float32)>,\n",
       " <tf.Variable 'dense_3/bias:0' shape=(10,) dtype=float32, numpy=array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.build(input_shape=(None, 3))\n",
    "model.weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**The summary method**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 906\n",
      "Trainable params: 906\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Naming models and layers with the `name` argument**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"my_example_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "my_first_layer (Dense)       (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "my_last_layer (Dense)        (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 906\n",
      "Trainable params: 906\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential(name=\"my_example_model\")\n",
    "model.add(layers.Dense(64, activation=\"relu\", name=\"my_first_layer\"))\n",
    "model.add(layers.Dense(10, activation=\"softmax\", name=\"my_last_layer\"))\n",
    "model.build((None, 3))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Specifying the input shape of your model in advance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.Input(shape=(3,)))\n",
    "model.add(layers.Dense(64, activation=\"relu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_34 (Dense)             (None, 64)                256       \n",
      "=================================================================\n",
      "Total params: 256\n",
      "Trainable params: 256\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_34 (Dense)             (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 906\n",
      "Trainable params: 906\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.add(layers.Dense(10, activation=\"softmax\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### The Functional API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### A simple example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**A simple Functional model with two `Dense` layers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(3,), name=\"my_input\")\n",
    "features = layers.Dense(64, activation=\"relu\")(inputs)\n",
    "outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(3,), name=\"my_input\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([None, 3])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tf.float32"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "features = layers.Dense(64, activation=\"relu\")(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([None, 64])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "my_input (InputLayer)        [(None, 3)]               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 906\n",
      "Trainable params: 906\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Multi-input, multi-output models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**A multi-input, multi-output Functional model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "vocabulary_size = 10000\n",
    "num_tags = 100\n",
    "num_departments = 4\n",
    "\n",
    "title = keras.Input(shape=(vocabulary_size,), name=\"title\")\n",
    "text_body = keras.Input(shape=(vocabulary_size,), name=\"text_body\")\n",
    "tags = keras.Input(shape=(num_tags,), name=\"tags\")\n",
    "\n",
    "features = layers.Concatenate()([title, text_body, tags])\n",
    "features = layers.Dense(64, activation=\"relu\")(features)\n",
    "\n",
    "priority = layers.Dense(1, activation=\"sigmoid\", name=\"priority\")(features)\n",
    "department = layers.Dense(\n",
    "    num_departments, activation=\"softmax\", name=\"department\")(features)\n",
    "\n",
    "model = keras.Model(inputs=[title, text_body, tags], outputs=[priority, department])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Training a multi-input, multi-output model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Training a model by providing lists of input & target arrays**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 3s 5ms/step - loss: 22.7059 - priority_loss: 0.3269 - department_loss: 22.3790 - priority_mean_absolute_error: 0.4972 - department_accuracy: 0.2750\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 27.9473 - priority_loss: 0.3313 - department_loss: 27.6160 - priority_mean_absolute_error: 0.5009 - department_accuracy: 0.2648\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "num_samples = 1280\n",
    "\n",
    "title_data = np.random.randint(0, 2, size=(num_samples, vocabulary_size))\n",
    "text_body_data = np.random.randint(0, 2, size=(num_samples, vocabulary_size))\n",
    "tags_data = np.random.randint(0, 2, size=(num_samples, num_tags))\n",
    "\n",
    "priority_data = np.random.random(size=(num_samples, 1))\n",
    "department_data = np.random.randint(0, 2, size=(num_samples, num_departments))\n",
    "\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=[\"mean_squared_error\", \"categorical_crossentropy\"],\n",
    "              metrics=[[\"mean_absolute_error\"], [\"accuracy\"]])\n",
    "model.fit([title_data, text_body_data, tags_data],\n",
    "          [priority_data, department_data],\n",
    "          epochs=1)\n",
    "model.evaluate([title_data, text_body_data, tags_data],\n",
    "               [priority_data, department_data])\n",
    "priority_preds, department_preds = model.predict([title_data, text_body_data, tags_data])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Training a model by providing dicts of input & target arrays**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 1s 5ms/step - loss: 27.8365 - priority_loss: 0.3313 - department_loss: 27.5052 - priority_mean_absolute_error: 0.5009 - department_accuracy: 0.2594\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 22.3076 - priority_loss: 0.3313 - department_loss: 21.9763 - priority_mean_absolute_error: 0.5009 - department_accuracy: 0.2648\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss={\"priority\": \"mean_squared_error\", \"department\": \"categorical_crossentropy\"},\n",
    "              metrics={\"priority\": [\"mean_absolute_error\"], \"department\": [\"accuracy\"]})\n",
    "model.fit({\"title\": title_data, \"text_body\": text_body_data, \"tags\": tags_data},\n",
    "          {\"priority\": priority_data, \"department\": department_data},\n",
    "          epochs=1)\n",
    "model.evaluate({\"title\": title_data, \"text_body\": text_body_data, \"tags\": tags_data},\n",
    "               {\"priority\": priority_data, \"department\": department_data})\n",
    "priority_preds, department_preds = model.predict(\n",
    "    {\"title\": title_data, \"text_body\": text_body_data, \"tags\": tags_data})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### The power of the Functional API: Access to layer connectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) ', 'for plot_model/model_to_dot to work.')\n"
     ]
    }
   ],
   "source": [
    "keras.utils.plot_model(model, \"ticket_classifier.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) ', 'for plot_model/model_to_dot to work.')\n"
     ]
    }
   ],
   "source": [
    "keras.utils.plot_model(model, \"ticket_classifier_with_shape_info.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Retrieving the inputs or outputs of a layer in a Functional model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.engine.input_layer.InputLayer at 0x1de9fc040a0>,\n",
       " <tensorflow.python.keras.engine.input_layer.InputLayer at 0x1de9fc20340>,\n",
       " <tensorflow.python.keras.engine.input_layer.InputLayer at 0x1de9fc20460>,\n",
       " <tensorflow.python.keras.layers.merge.Concatenate at 0x1de9fc04610>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x1de9fc04970>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x1de9fbf1760>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x1de99b60df0>]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<KerasTensor: shape=(None, 10000) dtype=float32 (created by layer 'title')>,\n",
       " <KerasTensor: shape=(None, 10000) dtype=float32 (created by layer 'text_body')>,\n",
       " <KerasTensor: shape=(None, 100) dtype=float32 (created by layer 'tags')>]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[3].input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 20100) dtype=float32 (created by layer 'concatenate')>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[3].output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Creating a new model by reusing intermediate layer outputs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "features = model.layers[4].output\n",
    "difficulty = layers.Dense(3, activation=\"softmax\", name=\"difficulty\")(features)\n",
    "\n",
    "new_model = keras.Model(\n",
    "    inputs=[title, text_body, tags],\n",
    "    outputs=[priority, department, difficulty])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) ', 'for plot_model/model_to_dot to work.')\n"
     ]
    }
   ],
   "source": [
    "keras.utils.plot_model(new_model, \"updated_ticket_classifier.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Subclassing the Model class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Rewriting our previous example as a subclassed model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**A simple subclassed model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "class CustomerTicketModel(keras.Model):\n",
    "\n",
    "    def __init__(self, num_departments):\n",
    "        super().__init__()\n",
    "        self.concat_layer = layers.Concatenate()\n",
    "        self.mixing_layer = layers.Dense(64, activation=\"relu\")\n",
    "        self.priority_scorer = layers.Dense(1, activation=\"sigmoid\")\n",
    "        self.department_classifier = layers.Dense(\n",
    "            num_departments, activation=\"softmax\")\n",
    "\n",
    "    def call(self, inputs):\n",
    "        title = inputs[\"title\"]\n",
    "        text_body = inputs[\"text_body\"]\n",
    "        tags = inputs[\"tags\"]\n",
    "\n",
    "        features = self.concat_layer([title, text_body, tags])\n",
    "        features = self.mixing_layer(features)\n",
    "        priority = self.priority_scorer(features)\n",
    "        department = self.department_classifier(features)\n",
    "        return priority, department"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model = CustomerTicketModel(num_departments=4)\n",
    "\n",
    "priority, department = model(\n",
    "    {\"title\": title_data, \"text_body\": text_body_data, \"tags\": tags_data})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 1s 4ms/step - loss: 33.4234 - output_1_loss: 0.3224 - output_2_loss: 33.1010 - output_1_mean_absolute_error: 0.4915 - output_2_accuracy: 0.2727\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 25.3511 - output_1_loss: 0.3296 - output_2_loss: 25.0216 - output_1_mean_absolute_error: 0.4991 - output_2_accuracy: 0.1187\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=[\"mean_squared_error\", \"categorical_crossentropy\"],\n",
    "              metrics=[[\"mean_absolute_error\"], [\"accuracy\"]])\n",
    "model.fit({\"title\": title_data,\n",
    "           \"text_body\": text_body_data,\n",
    "           \"tags\": tags_data},\n",
    "          [priority_data, department_data],\n",
    "          epochs=1)\n",
    "model.evaluate({\"title\": title_data,\n",
    "                \"text_body\": text_body_data,\n",
    "                \"tags\": tags_data},\n",
    "               [priority_data, department_data])\n",
    "priority_preds, department_preds = model.predict({\"title\": title_data,\n",
    "                                                  \"text_body\": text_body_data,\n",
    "                                                  \"tags\": tags_data})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Beware: What subclassed models don't support"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Mixing and matching different components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Creating a Functional model that includes a subclassed model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "class Classifier(keras.Model):\n",
    "\n",
    "    def __init__(self, num_classes=2):\n",
    "        super().__init__()\n",
    "        if num_classes == 2:\n",
    "            num_units = 1\n",
    "            activation = \"sigmoid\"\n",
    "        else:\n",
    "            num_units = num_classes\n",
    "            activation = \"softmax\"\n",
    "        self.dense = layers.Dense(num_units, activation=activation)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return self.dense(inputs)\n",
    "\n",
    "inputs = keras.Input(shape=(3,))\n",
    "features = layers.Dense(64, activation=\"relu\")(inputs)\n",
    "outputs = Classifier(num_classes=10)(features)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Creating a subclassed model that includes a Functional model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(64,))\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(inputs)\n",
    "binary_classifier = keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "class MyModel(keras.Model):\n",
    "\n",
    "    def __init__(self, num_classes=2):\n",
    "        super().__init__()\n",
    "        self.dense = layers.Dense(64, activation=\"relu\")\n",
    "        self.classifier = binary_classifier\n",
    "\n",
    "    def call(self, inputs):\n",
    "        features = self.dense(inputs)\n",
    "        return self.classifier(features)\n",
    "\n",
    "model = MyModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Remember: Use the right tool for the job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Using built-in training and evaluation loops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**The standard workflow: `compile()`, `fit()`, `evaluate()`, `predict()`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.2968 - accuracy: 0.9128 - val_loss: 0.1512 - val_accuracy: 0.9570\n",
      "Epoch 2/3\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.1652 - accuracy: 0.9537 - val_loss: 0.1192 - val_accuracy: 0.9691\n",
      "Epoch 3/3\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.1374 - accuracy: 0.9628 - val_loss: 0.1283 - val_accuracy: 0.9706\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.1148 - accuracy: 0.9701\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "def get_mnist_model():\n",
    "    inputs = keras.Input(shape=(28 * 28,))\n",
    "    features = layers.Dense(512, activation=\"relu\")(inputs)\n",
    "    features = layers.Dropout(0.5)(features)\n",
    "    outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
    "    model = keras.Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "(images, labels), (test_images, test_labels) = mnist.load_data()\n",
    "images = images.reshape((60000, 28 * 28)).astype(\"float32\") / 255\n",
    "test_images = test_images.reshape((10000, 28 * 28)).astype(\"float32\") / 255\n",
    "train_images, val_images = images[10000:], images[:10000]\n",
    "train_labels, val_labels = labels[10000:], labels[:10000]\n",
    "\n",
    "model = get_mnist_model()\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "model.fit(train_images, train_labels,\n",
    "          epochs=3,\n",
    "          validation_data=(val_images, val_labels))\n",
    "test_metrics = model.evaluate(test_images, test_labels)\n",
    "predictions = model.predict(test_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Writing your own metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Implementing a custom metric by subclassing the `Metric` class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class RootMeanSquaredError(keras.metrics.Metric):\n",
    "\n",
    "    def __init__(self, name=\"rmse\", **kwargs):\n",
    "        super().__init__(name=name, **kwargs)\n",
    "        self.mse_sum = self.add_weight(name=\"mse_sum\", initializer=\"zeros\")\n",
    "        self.total_samples = self.add_weight(\n",
    "            name=\"total_samples\", initializer=\"zeros\", dtype=\"int32\")\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        y_true = tf.one_hot(y_true, depth=tf.shape(y_pred)[1])\n",
    "        mse = tf.reduce_sum(tf.square(y_true - y_pred))\n",
    "        self.mse_sum.assign_add(mse)\n",
    "        num_samples = tf.shape(y_pred)[0]\n",
    "        self.total_samples.assign_add(num_samples)\n",
    "\n",
    "    def result(self):\n",
    "        return tf.sqrt(self.mse_sum / tf.cast(self.total_samples, tf.float32))\n",
    "\n",
    "    def reset_state(self):\n",
    "        self.mse_sum.assign(0.)\n",
    "        self.total_samples.assign(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.2942 - accuracy: 0.9132 - rmse: 7.1819 - val_loss: 0.1446 - val_accuracy: 0.9553 - val_rmse: 7.3611\n",
      "Epoch 2/3\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.1643 - accuracy: 0.9538 - rmse: 7.3542 - val_loss: 0.1353 - val_accuracy: 0.9640 - val_rmse: 7.4100\n",
      "Epoch 3/3\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.1404 - accuracy: 0.9625 - rmse: 7.3868 - val_loss: 0.1074 - val_accuracy: 0.9717 - val_rmse: 7.4196\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1086 - accuracy: 0.9713 - rmse: 7.4331\n"
     ]
    }
   ],
   "source": [
    "model = get_mnist_model()\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\", RootMeanSquaredError()])\n",
    "model.fit(train_images, train_labels,\n",
    "          epochs=3,\n",
    "          validation_data=(val_images, val_labels))\n",
    "test_metrics = model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Using callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### The EarlyStopping and ModelCheckpoint callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Using the `callbacks` argument in the `fit()` method**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.2942 - accuracy: 0.9115 - val_loss: 0.1522 - val_accuracy: 0.9562\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.1638 - accuracy: 0.9540 - val_loss: 0.1219 - val_accuracy: 0.9679\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.1383 - accuracy: 0.9626 - val_loss: 0.1186 - val_accuracy: 0.9712\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.1278 - accuracy: 0.9668 - val_loss: 0.1089 - val_accuracy: 0.9743\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.1161 - accuracy: 0.9701 - val_loss: 0.1128 - val_accuracy: 0.9749\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.1077 - accuracy: 0.9733 - val_loss: 0.1126 - val_accuracy: 0.9767\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.1067 - accuracy: 0.9749 - val_loss: 0.1157 - val_accuracy: 0.9769\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.1051 - accuracy: 0.9763 - val_loss: 0.1036 - val_accuracy: 0.9798\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.0991 - accuracy: 0.9778 - val_loss: 0.1121 - val_accuracy: 0.9775\n",
      "Epoch 10/10\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.0940 - accuracy: 0.9789 - val_loss: 0.1175 - val_accuracy: 0.9787\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1e0c7937dc0>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callbacks_list = [\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_accuracy\",\n",
    "        patience=2,\n",
    "    ),\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath=\"checkpoint_path.keras\",\n",
    "        monitor=\"val_loss\",\n",
    "        save_best_only=True,\n",
    "    )\n",
    "]\n",
    "model = get_mnist_model()\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "model.fit(train_images, train_labels,\n",
    "          epochs=10,\n",
    "          callbacks=callbacks_list,\n",
    "          validation_data=(val_images, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"checkpoint_path.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Writing your own callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Creating a custom callback by subclassing the `Callback` class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "class LossHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs):\n",
    "        self.per_batch_losses = []\n",
    "\n",
    "    def on_batch_end(self, batch, logs):\n",
    "        self.per_batch_losses.append(logs.get(\"loss\"))\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        plt.clf()\n",
    "        plt.plot(range(len(self.per_batch_losses)), self.per_batch_losses,\n",
    "                 label=\"Training loss for each batch\")\n",
    "        plt.xlabel(f\"Batch (epoch {epoch})\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.legend()\n",
    "        plt.savefig(f\"plot_at_epoch_{epoch}\")\n",
    "        self.per_batch_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.2940 - accuracy: 0.9127 - val_loss: 0.1440 - val_accuracy: 0.9585\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.1651 - accuracy: 0.9536 - val_loss: 0.1209 - val_accuracy: 0.9669\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.1408 - accuracy: 0.9629 - val_loss: 0.1207 - val_accuracy: 0.9698\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.1276 - accuracy: 0.9671 - val_loss: 0.1086 - val_accuracy: 0.9728\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.1190 - accuracy: 0.9702 - val_loss: 0.1081 - val_accuracy: 0.9747\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.1073 - accuracy: 0.9732 - val_loss: 0.1102 - val_accuracy: 0.9768\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.1072 - accuracy: 0.9746 - val_loss: 0.1135 - val_accuracy: 0.9774\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.1022 - accuracy: 0.9759 - val_loss: 0.1041 - val_accuracy: 0.9782\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.0999 - accuracy: 0.9766 - val_loss: 0.1128 - val_accuracy: 0.9776\n",
      "Epoch 10/10\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.0949 - accuracy: 0.9784 - val_loss: 0.1196 - val_accuracy: 0.9776\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1dec9eaec10>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAEGCAYAAACO8lkDAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAArmklEQVR4nO3de3xdZZ33/c9v751zmrT0BLRACxQLPQJpLS3WFkE5KeDAM1QGVFQODqLycCgDIsPt3CPq7eMw4vAgIjPKCN6iiFJvsAqUk9KA5dAjBQoNpec2h+a0s/O7/1grYTdJs3fTriZhfd+vV1/JWnvttX7ZafZ3X9e11rXM3REREcmW6O8CRERk4FE4iIhINwoHERHpRuEgIiLdKBxERKSbVH8XsLdGjBjh48aN6+8yREQGlRdffHGru4/Md/tIw8HMTgf+DUgC97j7t7s8fh1wUVYtxwIj3X37nvY5btw4qqurI6pYROSDycze3pvtI+tWMrMkcCdwBnAcsMDMjsvext2/6+7T3X06cCPwVG/BICIiB0aUYw4zgbXu/qa7twIPAOf0sv0C4BcR1iMiInmKMhzGAOuzlmvCdd2YWSlwOvDQHh6/zMyqzax6y5Yt+71QERHZXZRjDtbDuj3N1fFJ4Nk9dSm5+93A3QBVVVWa70MOqHQ6TU1NDc3Nzf1dikhOxcXFjB07loKCgn3aT5ThUAMclrU8Ftiwh20vRF1KMkDV1NQwZMgQxo0bh1lPn3lEBgZ3Z9u2bdTU1DB+/Ph92leU3UpLgQlmNt7MCgkC4JGuG5lZJfBR4LcR1iLSZ83NzQwfPlzBIAOemTF8+PD90sqNrOXg7m1mdhXwGMGprPe6+3IzuyJ8/K5w0/OAx919V1S1iOwrBYMMFvvr/2qk1zm4+yJgUZd1d3VZvg+4L8o6AFZvrOfRVzZwyexxjCgvivpwIiKDWmymz3h9cz13/Hkt23e19ncpInnbtm0b06dPZ/r06Rx88MGMGTOmc7m1tff/y9XV1Vx99dU5jzF79uz9UuuTTz7J2WefvV/21dXTTz/NpEmTmD59Ok1NTZEcIx/5/ozz5s3bq4t1ly1bxqJFi3JuV15envc+99Wgmz6jr6zHk6dEBrbhw4ezbNkyAG699VbKy8u59tprOx9va2sjler5z7iqqoqqqqqcx3juuef2S61Ruv/++7n22mv5/Oc/n9f2mUyGZDIZcVX7z7Jly6iurubMM8/s71I6xabl0EE3vpPB7nOf+xzXXHMN8+fP54YbbuCFF15g9uzZHH/88cyePZvVq1cDu3/KvfXWW7n00kuZN28eRx55JHfccUfn/jo+jT755JPMmzeP888/n4kTJ3LRRRfRcafIRYsWMXHiRE4++WSuvvrqnJ+et2/fzrnnnsvUqVOZNWsWr7zyCgBPPfVUZ8vn+OOPp76+nvfee4+5c+cyffp0Jk+ezNNPP73bvu655x5++ctfctttt3XWdN111zF58mSmTJnCgw8+2Fn//Pnz+cxnPsOUKVO61fT4449z0kknccIJJ3DBBRfQ0NAAwG233caMGTOYPHkyl112WefPvHbtWk499VSmTZvGCSecwBtvvAFAQ0NDj69RVz//+c+ZPXs2kydP5oUXXgDo8XfV2trKLbfcwoMPPsj06dN58MEHaWho4POf/zxTpkxh6tSpPPTQ+5eA3XTTTUybNo1Zs2axadOmXn8P+yI+LYew4eB7vNRCJLd//t1yVmyo26/7PO7QCr75yUl79Zw1a9awePFikskkdXV1LFmyhFQqxeLFi/mnf/qn3d5MOqxatYonnniC+vp6PvShD3HllVd2Oxf+b3/7G8uXL+fQQw9lzpw5PPvss1RVVXH55ZezZMkSxo8fz4IFC3LW981vfpPjjz+ehx9+mD//+c9ccsklLFu2jO9973vceeedzJkzh4aGBoqLi7n77rv5xCc+wU033UQmk6GxsXG3fX3xi1/kmWee4eyzz+b888/noYceYtmyZbz88sts3bqVGTNmMHfuXCB4833ttde6nca5detWvvWtb7F48WLKysq4/fbb+f73v88tt9zCVVddxS233ALAxRdfzO9//3s++clPctFFF7Fw4ULOO+88mpubaW9vZ/369T2+RieffHK312DXrl0899xzLFmyhEsvvZTXXnuNiRMn9vi7uu2226iuruaHP/whADfccAOVlZW8+uqrAOzYsaNzn7NmzeJf/uVfuP766/nxj3/MzTffnPP30RfxCYfwq1oO8kFwwQUXdHab1NbW8tnPfpbXX38dMyOdTvf4nLPOOouioiKKiooYNWoUmzZtYuzYsbttM3PmzM5106dPZ926dZSXl3PkkUd2vuEuWLCAu+++u9f6nnnmmc6AOuWUU9i2bRu1tbXMmTOHa665hosuuohPf/rTjB07lhkzZnDppZeSTqc599xzmT59es59L1iwgGQyyejRo/noRz/K0qVLqaioYObMmT2e3/+Xv/yFFStWMGfOHABaW1s56aSTAHjiiSf4zne+Q2NjI9u3b2fSpEnMmzePd999l/POOw8ILizr7TXqKRw6QnTu3LnU1dWxc+dO6uvr8/pdLV68mAceeKBzediwYQAUFhZ2ttpOPPFE/vjHP/b6Wu2L+IRDR8tB4SD7YG8/4UelrKys8/tvfOMbzJ8/n9/85jesW7eOefPm9ficoqL3z9JLJpO0tbXltc2euk1609NzzIyFCxdy1llnsWjRImbNmsXixYuZO3cuS5Ys4dFHH+Xiiy/muuuu45JLLtmrfXfIfl26Pue0007jF7/Y/Vrb5uZmvvzlL1NdXc1hhx3GrbfeSnNzc6/HyOd17Ph5uy7n+7ty9x5PSS0oKOhc39ux94cYjTloQFo+mGpraxkzJpi27L777tvv+584cSJvvvkm69atA+js4+/N3Llzuf/++4FgLGDEiBFUVFTwxhtvMGXKFG644QaqqqpYtWoVb7/9NqNGjeJLX/oSX/jCF3jppZdy7vvBBx8kk8mwZcsWlixZwsyZM3t9zqxZs3j22WdZu3YtAI2NjaxZs6bzYrERI0bQ0NDAr371KwAqKioYO3YsDz/8MAAtLS3durty6XidnnnmGSorK6msrNzj72rIkCHU19d3Ln/84x/v7GKC97uVDqQYhUNAYw7yQXP99ddz4403MmfOHDKZzH7ff0lJCT/60Y84/fTTOfnkkxk9ejSVlZW9PufWW2+lurqaqVOnsnDhQv7zP/8TgB/84AdMnjyZadOmUVJSwhlnnMGTTz7ZOUD90EMP8dWvfrXXfZ933nlMnTqVadOmccopp/Cd73yHgw8+uNfnjBw5kvvuu48FCxZ0DpKvWrWKoUOH8qUvfYkpU6Zw7rnnMmPGjM7n/OxnP+OOO+5g6tSpzJ49m40bN+b5igWGDRvG7NmzueKKK/jJT34C7Pl3NX/+fFasWNE5IH3zzTezY8eOztfqiSee2Ktj7w/WlyZjf6qqqvK+3OznseUbufxnL/L7r5zM5DG9/8cWybZy5UqOPfbY/i6jXzU0NFBeXo6784//+I9MmDCBr3/96/1dluxBT/9nzexFd899bnMoNi0HdSqJ9N2Pf/xjpk+fzqRJk6itreXyyy/v75IkYjEakA7iYZA1lEQGhK9//etqKcSMWg4ieRhs3a8SX/vr/2pswqGDBqRlbxUXF7Nt2zYFhAx4HfdzyL4uo69i1K0UfNXft+ytsWPHUlNTg25RK4NBx53g9lX8wqF/y5BBqKCgYJ/vqiUy2MSmW6ljVlZ1DYiI5BabcNCItIhI/uITDiG1G0REcotNOGhWVhGR/MUnHDpnOFQ6iIjkEp9w6O8CREQGkdiEQwd1K4mI5BabcNB1DiIi+Ys0HMzsdDNbbWZrzWzhHraZZ2bLzGy5mT0VWS1o4j0RkXxFdoW0mSWBO4HTgBpgqZk94u4rsrYZCvwION3d3zGzUdHVE3zVRXAiIrlF2XKYCax19zfdvRV4ADinyzafAX7t7u8AuPvmqIrRgLSISP6iDIcxwPqs5ZpwXbZjgGFm9qSZvWhmPd5V3MwuM7NqM6ve18nP1G4QEcktynDo6cN61/fmFHAicBbwCeAbZnZMtye53+3uVe5eNXLkyH2qRr1KIiK5RTkraw1wWNbyWGBDD9tsdfddwC4zWwJMA9bs72I6B6TVdhARySnKlsNSYIKZjTezQuBC4JEu2/wW+IiZpcysFPgwsDKKYnSBtIhI/iJrObh7m5ldBTwGJIF73X25mV0RPn6Xu680s/8DvAK0A/e4+2tR1KMBaRGR/EV6sx93XwQs6rLuri7L3wW+G2Udux3vQB1IRGQQi9EV0roITkQkXzEKh+CrBqRFRHKLTziEX9VyEBHJLT7hoBFpEZG8xSYcOqjhICKSW4zCoWNAWvEgIpJLbMJB93MQEclffMKh4xulg4hITrEJBxERyV9swqHzIjg1HUREcopPOIRfNR4tIpJbfMJB93MQEclbfMJB87KKiOQtNuHQQQ0HEZHcYhMO73crKR5ERHKJTTh0UDSIiOQWm3DQgLSISP7iEw4akBYRyVtswuF9ajqIiOQSm3BQt5KISP7iFw79W4aIyKAQn3DovJ9DPxciIjIIxCccNB4tIpK3SMPBzE43s9VmttbMFvbw+DwzqzWzZeG/W6KsBzQrq4hIPlJR7djMksCdwGlADbDUzB5x9xVdNn3a3c+Oqo7OesKv6lYSEcktypbDTGCtu7/p7q3AA8A5ER6vVxqQFhHJX5ThMAZYn7VcE67r6iQze9nM/mBmk3rakZldZmbVZla9ZcuWPpbTMSCteBARySXKcOhpCLjrO/NLwBHuPg34d+Dhnnbk7ne7e5W7V40cObJvxWhAWkQkb1GGQw1wWNbyWGBD9gbuXufuDeH3i4ACMxsRYU0iIpKHKMNhKTDBzMabWSFwIfBI9gZmdrCFN3c2s5lhPduiKEYD0iIi+YvsbCV3bzOzq4DHgCRwr7svN7MrwsfvAs4HrjSzNqAJuNAjGhQIM0insoqI5CGycIDOrqJFXdbdlfX9D4EfRllDBw05iIjkLzZXSHdQt5KISG6xCQfNyioikr/4hEPHdQ79XIeIyGAQn3DobDkoHkREcolNOIiISP5iFw5qN4iI5BabcOicPkPpICKSU4zCQRfBiYjkKz7hEH7VeLSISG7xCQddIi0ikrfYhEMHNRxERHKLTTh0XgSndBARySk+4dB5m1Clg4hILvEJh/CrWg4iIrnFJhw0Z7eISP7iEw4hNRxERHKLTTh0DEirX0lEJLf4hEPngLSIiOQSn3Do7wJERAaR2IRDB/UqiYjkFptw6Jx4T+kgIpJTfMIh/KpoEBHJLT7hoJOVRETyFmk4mNnpZrbazNaa2cJetpthZhkzOz+yWjQkLSKSt8jCwcySwJ3AGcBxwAIzO24P290OPBZVLdnUcBARyS3KlsNMYK27v+nurcADwDk9bPcV4CFgc4S18P41cIoHEZFcogyHMcD6rOWacF0nMxsDnAfc1duOzOwyM6s2s+otW7b0qRjd7EdEJH95hYOZlZlZIvz+GDP7lJkV5HpaD+u6fmz/AXCDu2d625G73+3uVe5eNXLkyHxK3mMxajiIiOSWynO7JcBHzGwY8CegGvh74KJenlMDHJa1PBbY0GWbKuCB8BqEEcCZZtbm7g/nWVfeTE0HEZG85dutZO7eCHwa+Hd3P49gkLk3S4EJZjbezAqBC4FHsjdw9/HuPs7dxwG/Ar4cRTDsdkwNSYuI5JR3OJjZSQQthUfDdb22Oty9DbiK4CyklcAv3X25mV1hZlf0teC+UreSiEj+8u1W+hpwI/Cb8A3+SOCJXE9y90XAoi7rehx8dvfP5VlLn2hWVhGR/OUVDu7+FPAUQDgwvdXdr46ysP2t4yI4tRxERHLL92yl/zazCjMrA1YAq83sumhL2780Hi0ikr98xxyOc/c64FyCbqLDgYujKipKGpAWEckt33AoCK9rOBf4rbunGaTd9+pWEhHJLd9w+P+BdUAZsMTMjgDqoioqCupWEhHJX74D0ncAd2StetvM5kdTUjQ0K6uISP7yHZCuNLPvd8xvZGb/i6AVMeho4j0Rkdzy7Va6F6gH/p/wXx3w06iKioJu9iMikr98L4I7yt3/Lmv5n81sWQT1REa3CRURyV++LYcmMzu5Y8HM5gBN0ZQUjY6J99RyEBHJLd+WwxXAf5lZZbi8A/hsNCVFQ8PRIiL5y/dspZeBaWZWES7XmdnXgFcirC0SughORCS3vboTnLvXhVdKA1wTQT2R0YC0iEj+9uU2oYOqp6ZzzKGf6xARGQz2JRwG5/usmg4iIjn1OuZgZvX0HAIGlERSUYQ0hYaISH5y3c1tyIEq5EBRu0FEJLd96VYadAz1KomI5CNe4WCmU1lFRPIQr3BALQcRkXzEKxw0IC0ikpdYhQNoQFpEJB+xCgfD1K0kIpKHSMPBzE43s9VmttbMFvbw+Dlm9oqZLQtvInRyT/vZfwVpbiURkXzkOyvrXjOzJHAncBpQAyw1s0fcfUXWZn8CHnF3N7OpwC+BiZHVFNWORUQ+YKJsOcwE1rr7m+7eCjwAnJO9gbs3+Pv37SzjQAwJqOEgIpJTlOEwBliftVwTrtuNmZ1nZquAR4FLe9qRmV3Wcf/qLVu29LkgM2WDiEg+ogyHnnpxur03u/tv3H0icC7wP3rakbvf7e5V7l41cuTIfSjIcI1Ii4jkFGU41ACHZS2PBTbsaWN3XwIcZWYjoirITBfBiYjkI8pwWApMMLPxZlYIXAg8kr2BmR1t4Y0WzOwEoBDYFlVBGpAWEclPZGcruXubmV0FPAYkgXvdfbmZXRE+fhfwd8AlZpYGmoC/94j7fdRwEBHJLbJwAHD3RcCiLuvuyvr+duD2KGvIljCjXf1KIiI5xesKaY05iIjkJVbhkEio5SAiko9YhUNS3UoiInmJVTiYGe3KBhGRnGIVDgmDdqWDiEhOsQqHpMYcRETyEqtwSKhbSUQkL7EKB1O3kohIXmIVDroITkQkP7EKh2DMob+rEBEZ+GIVDmao5SAikodYhYO6lURE8hOrcEia0d7e31WIiAx8sQoHdSuJiOQnVuGgbiURkfzEKhx0tpKISH5iFQ4JdSuJiOQlVuFgZmTUdBARySlW4ZBMmO4EJyKSh1iFg7qVRETyE6twULeSiEh+YhUOBUmjTeEgIpJTrMKhKJWktU2XSIuI5BJpOJjZ6Wa22szWmtnCHh6/yMxeCf89Z2bToqynKJWgpS0T5SFERD4QIgsHM0sCdwJnAMcBC8zsuC6bvQV81N2nAv8DuDuqeqAjHNRyEBHJJcqWw0xgrbu/6e6twAPAOdkbuPtz7r4jXPwLMDbCeihKJWlJKxxERHKJMhzGAOuzlmvCdXvyBeAPEdZDUYG6lURE8pGKcN/Ww7oeTxUys/kE4XDyHh6/DLgM4PDDD+9zQepWEhHJT5QthxrgsKzlscCGrhuZ2VTgHuAcd9/W047c/W53r3L3qpEjR/a5oEKFg4hIXqIMh6XABDMbb2aFwIXAI9kbmNnhwK+Bi919TYS1AMGYQ6bdacsoIEREehNZt5K7t5nZVcBjQBK4192Xm9kV4eN3AbcAw4EfmRlAm7tXRVVTUSrIwpa2dlLJWF3iISKyV6Icc8DdFwGLuqy7K+v7LwJfjLKGbNnhUFZ0oI4qIjL4xOrjc1FBEkBXSYuI5BCvcOhsOeh0VhGR3sQsHIKWg85YEhHpXczCIWw56CppEZFexSocCtWtJCKSl1iFQ/bZSiIismfxCoeCjjEHtRxERHoTr3DQmIOISF7iGQ7qVhIR6VW8wkEXwYmI5CVe4aCzlURE8hLTcFDLQUSkN7EKh0KFg4hIXuIVDsmOs5XUrSQi0ptYhYOZ6VahIiJ5iFU4gO4jLSKSj/iFQ0FSZyuJiOQQv3BIJXSFtIhIDvEMh4zCQUSkNzEMh6RaDiIiOcQvHAoSNOtUVhGRXsUuHIYUF1Df0tbfZYiIDGixC4eK4hT1Ten+LkNEZECLNBzM7HQzW21ma81sYQ+PTzSz582sxcyujbKWDpUlBWzb1Yq7H4jDsfK9Ov64YhN/WrmJ6nXbufxn1Zz6/ad4a+uuA3J8EZG+SEW1YzNLAncCpwE1wFIze8TdV2Rtth24Gjg3qjq6mjCqnNqmNJvrWxhdURzZcd7Y0kDSjDP+7ekeH//Uvz/Ddy+YyqnHjiaVjF0Dbp81pzNsrG3msINKSSasv8sR+cCJLByAmcBad38TwMweAM4BOsPB3TcDm83srAjr2M0Rw8sAqNnRFEk4fPsPq1i8chNrNzd0rvvIhBEAvPpuLTsb01w1/2j+tGozV/z8JQ4/qJTL5h7Jx44dxSGVJTn3//qmev77hXcYO6yUgyuKWb6hliNHltPQnKa4IEltU5rDDiplxYY6jj98KMeMHsL2Xa38w0/+yolHDGP2UcOZc/QIKooLeHL1ZlZurGfKmEqWvrWd8SPKOGJEGWOGljDx4CE0pzO8tXUXw8uLGD8ieN3Wb28k0+68saWBdMZJZ9ppd2f8iDLGDiulIGkMKS4AoC3TvlfB19DSxo5drYwdVoLZ+2/4S9Zs4a9vbWP7rlaKUkk21TXzh9c2AlBckGDCqCFMGF1OWWGKEeVFLF23nbrmNEcML+PokeWUFSVxh4qSFJMOrWTkkCKKUgmGlhbS0pZh7eYGduxKYwaphJFpd1ra2nmvtpl3tjcCsKW+hcJUgnSmndqmNAmDtoxz6NASxg4rYeSQ4DXKtDuZdqcglaAwmWB4eSHDy4o6J33M9tNn3+LZtdsYVlrAms0N4E5FSQGlhUlGlBeRShhN6QyGUVSQoKQwyUGlhQBk3NlS38LOxuD3ffhBpRwW1nHo0BKKw3uX5POaJwxKC6N8K5DBKMr/EWOA9VnLNcCHIzxeXg4ZGgTChp1NnHjEsP267ydWbeaup94A4Ijhpby9LXhj+dFFJ3S+Yba2tVOYSnDlvKP41qMrWPTqRm5++DVufhhOPGIYJx05nKJUgk+fOJYxQ0twd77yi7+x8r06NtY2s6u172daPbVmC0+u3tLn5xcXJGjOcRqwGYwbXsaW+hYaWtoYN7yUYw+p4KCyQg6pLGZIcQFbG1rY2tDC0NJCChJGQ0uGhME9z7wFwJDiFKOGFDFueBn1LW288Nb23Y5RmEwwZmgJHx5/EAeVFbJ6Uz1Pv76VhuY2msIz0Q4qK2T7rlZ+9/KGPdaaShht7bm7F1MJY0hxCjOjOZ3hsGGltLuTTFgYRLlPcBhaWsCI8iIqilNk2p1drUEoFSSNsqIg1A4dWkJtU5qNtc385c3tZNqd0sLgTT6daWdXS4bWLtfojCgPfs7sH8MMDqko5vDhpYwoL+KQymIKUwkOKiuiobmNNZvraUln2NGY5sW3d3S+XkWpBEOKUwwrLaS0MElZUYrKkgIqSgqoKC6gsqSAlrYMWxtaaGzNUJBMZP1cBZQXpYIQKwjCra29ndLCVOeUNaWFSdrdKUwmcIIPaKlE8POXFSUpSuUXaHJgRBkOPbX1+9TRb2aXAZcBHH744ftSU+en89c31e/Tfnpy77PBm9uDl83iw0cOpz78NF+Q9em54xNkWVGKf/30VP75U5P53y+u52fPv82aTfWdf6z/649rKCtM4kBjl0B4+B/nUFGc4u3tjRQkEqSSxoadTWTandbwk+0Jhw+jOZ1hxXt11DW1MW1sJZ+YdDCrw2Ms31BLYTLBBVWHUZRKUNecZtKhlSzfUMvG2hZWvFfL829sI5VIMGP8MDbVtVBelKJmRyNHjixndEUxkw+tIJVM0O7OtoZW1m9vZNuuVtZt3UU6087Ro8o5pLKYle/VUbOjqdsbcSphZNwpK0x1nl581pRDqCwtoGZHE+/ubKKkMMnZUw/hG2cfR0EyQXlRCjN2e02zNaczpDPtnWG8q6WNtoyzbVcLmXZn5cZ6apvSNLdm2NLQQmEyQXlxig8dPISSgiR1TWkKUglqG9NUlhZw7MEVjK4oAtitNZOtoaWNjbXNrNu6CzNImFHf0oYBdc1ptta3dgbitl2tFBcEb4jHHlLBt86ZTGVpQV7/v9rbnV2tbSTMSJhRmEqQTBitbe1s2NnE+h2NbKlv4Z3tjbyzrZF3tjfy2ru1/HHFpt3mE6soTnHo0BLc4dI54xleXkjNjkZqm9Jk2p0du9JsbWhl3bZG6prS1Dald/vdJRNGSUGSdKZ9v85TVpA0ilNJWjLtFCUTnX8rFSXvf7AaUV5IZdh6MqCsKMnI8iJGDiliSHFBZ6ANLS2gIJmgrilNUzrDlvrg/29pYZLmtnYqilMUJBMkzDoDraQgSXNbhsJkglQiOHYyaRQkDAzqmoJWVklh0BJtbWtnxJAiygqTNLS00dLWHgRkKrHH/yvZ6prTNIctw8Lw5y1IGu9sb2RXS4Y3tjRgFrzem+taeK+2iZnjh3PacaP322veG4tqYNbMTgJudfdPhMs3Arj7v/aw7a1Ag7t/L9d+q6qqvLq6us91uTvjb1wEwD2XVHFqlxd6zaZ63tjcwBlTDun23MUrNrFu2y4+PH446fZ2Jh1aQVEqyWPLNzJ+RBlfvv8lJowq5z/+4cQ+1/fi29v5y5vbWbWxnj+8+h4jhwRvTEuun4/BoB6faGnL0NDcxsa6ZiaMGkLCIJ1xSgqD+a7a24M/PNm/3J10xqlrToetg/zCKPv5zengQ0dhKsHQkgIS4ThPY2sbW+tbqW9J09DcRmvYwtm2q4W2jNPuQRddcSpBQ0sbyUTQNWdAeXGK8qIUu1ra2NWaob65jeZ0hqKCBK1t7bS2teMQvMG3ZqgITybZ2dgavPm609DSxpb6lrxab1EpCrsbsz/7FKYSFKUSFBckSYWvlTs4TrsHXa47GvfurMmisMfha6ce06c6zexFd6/Kd/soWw5LgQlmNh54F7gQ+EyEx8tLdqIvXrmpWzh8/qdLeXdnE4uvmcvzb2xj/sRRHFxRTDJhfPG/uofSjHHDWLpuR+fyhFHl+1TfiUccxIlHHBQsLDh+n/Y10BSlkhSVJxleXtS5rqMnQV0K0TEzClPGiKzXfW+fX1KY7DG4SwtTHD68/8crmtMZGlraaGzJsLOpldqmNC3pdoaWFlCYSlBZUkBbu7OzMR12c2VIZxz34ENLU2uGpnSGolTQIkpn2kmY0dbeHmxH0OJqD4OyJZ2hpDDJzsY0WxtaKC1MMby8MGhBpNtpbsvQkm6npS1DWyZIjY5WZfAWZJQVJjkiHMtrbQuO2drWzuiKIoaWFjJqSBGVJQWkM86oIUUMLS3Iq0Wyv0T2W3X3NjO7CngMSAL3uvtyM7sifPwuMzsYqAYqgHYz+xpwnLvXRVVXtp6axJkw/k/9/pJgxW+XM+2woXzx5PE97iM7GIBIz4ASkZ4VFySDQfhyOJzS/i7nAyHSyHf3RcCiLuvuyvp+IzA2yhp6ctKRw3n+zW2sD89EyTasrJCNdc27rXt5/U6+8ou/AXDHguM5c/LBmBn/c9FKxg4roawoxVEjy/nVizXceObEA/IziIhEqf/bg/3gvktn8P/+8mWeWbsVd9+tqdbU2sYnJo3mseWbALh87pGs3FjPkjXBWT6fmnZo57bfOPu43fa7v89+EhHpL7EMh6JUkhMOH8bvX3mPd3c2cc2DL3PVKUdTVpRk3bZGTjpqOI9efTJbG1r56DEjAfjzqk0kE4N3MFhEZG/EMhwAjg4Hjn+7bAMvrNvOJfe+0PnY2s0NTDq0crftT5l4YE4fExEZCGL7UbgjHL772Opuj82fOOpAlyMiMqDENhwOqdz9rKKh4YVI5x0/his/elR/lCQiMmDEtlvJzBhWWsCOxjQfmTCCn33hw+xsbGVoePWliEicxTYcAP73FbN59JX3uPpjRwMoGEREQrEOh6NHlfPVUyf0dxkiIgNObMccRERkzxQOIiLSjcJBRES6UTiIiEg3CgcREelG4SAiIt0oHEREpBuFg4iIdBPZPaSjYmZbgLf7+PQRwNb9WM7+pNr6RrX1jWrrm8Fc2xHuPjLfnQ26cNgXZla9NzfYPpBUW9+otr5RbX0Tp9rUrSQiIt0oHEREpJu4hcPd/V1AL1Rb36i2vlFtfROb2mI15iAiIvmJW8tBRETyoHAQEZFuYhMOZna6ma02s7VmtrAfjn+YmT1hZivNbLmZfTVcf5CZ/dHMXg+/Dst6zo1hvavN7BMR15c0s7+Z2e8HUl3h8Yaa2a/MbFX4+p00EOozs6+Hv8vXzOwXZlbcn3WZ2b1mttnMXstat9f1mNmJZvZq+NgdZmYR1fbd8Hf6ipn9xsyGDpTash671szczEYMpNrM7Cvh8Zeb2Xciqc3dP/D/gCTwBnAkUAi8DBx3gGs4BDgh/H4IsAY4DvgOsDBcvxC4Pfz+uLDOImB8WH8ywvquAf4b+H24PCDqCo/5n8AXw+8LgaH9XR8wBngLKAmXfwl8rj/rAuYCJwCvZa3b63qAF4CTAAP+AJwRUW0fB1Lh97cPpNrC9YcBjxFcdDtioNQGzAcWA0Xh8qgoaotLy2EmsNbd33T3VuAB4JwDWYC7v+fuL4Xf1wMrCd5gziF48yP8em74/TnAA+7e4u5vAWsJfo79zszGAmcB92St7ve6wtoqCP5AfgLg7q3uvnOA1JcCSswsBZQCG/qzLndfAmzvsnqv6jGzQ4AKd3/eg3eV/8p6zn6tzd0fd/e2cPEvwNiBUlvo/wOuB7LP2hkItV0JfNvdW8JtNkdRW1zCYQywPmu5JlzXL8xsHHA88FdgtLu/B0GAAKPCzQ5kzT8g+CNoz1o3EOqCoLW3Bfhp2O11j5mV9Xd97v4u8D3gHeA9oNbdH+/vunqwt/WMCb8/0HVeSvCJdkDUZmafAt5195e7PNTvtQHHAB8xs7+a2VNmNiOK2uISDj31r/XLObxmVg48BHzN3et627SHdfu9ZjM7G9js7i/m+5Qe1kX5WqYImtX/4e7HA7sIukf25EC9bsMIPqmNBw4FyszsH/q7rr2wp3oOeJ1mdhPQBtzfsWoPNRyo320pcBNwS08P76GGA/m6pYBhwCzgOuCX4RjCfq0tLuFQQ9B/2GEsQRfAAWVmBQTBcL+7/zpcvSls9hF+7WgiHqia5wCfMrN1BN1tp5jZzwdAXR1qgBp3/2u4/CuCsOjv+k4F3nL3Le6eBn4NzB4AdXW1t/XU8H73TuR1mtlngbOBi8Iuj4FQ21EEof9y+HcxFnjJzA4eALURHuvXHniBoMU/Yn/XFpdwWApMMLPxZlYIXAg8ciALCJP9J8BKd/9+1kOPAJ8Nv/8s8Nus9ReaWZGZjQcmEAwq7VfufqO7j3X3cQSvy5/d/R/6u66s+jYC683sQ+GqjwErBkB97wCzzKw0/N1+jGAcqb/r6mqv6gm7nurNbFb4c12S9Zz9ysxOB24APuXujV1q7rfa3P1Vdx/l7uPCv4sagpNJNvZ3baGHgVMAzOwYgpM0tu732vZ1NH2w/APOJDhD6A3gpn44/skETblXgGXhvzOB4cCfgNfDrwdlPeemsN7V7IczH/KocR7vn600kOqaDlSHr93DBE3qfq8P+GdgFfAa8DOCs0T6rS7gFwTjH2mCN7Qv9KUeoCr8md4Afkg4k0IEta0l6CPv+Hu4a6DU1uXxdYRnKw2E2gjC4OfhsV4CTomiNk2fISIi3cSlW0lERPaCwkFERLpROIiISDcKBxER6UbhICIi3SgcZNAxs4yZLTOzl83sJTObnWP7oWb25Tz2+6SZ5bxBu5kdYuHstVEzs1vN7No8tvt7C2Y37TpL51Vm9vloq5QPIoWDDEZN7j7d3acBNwL/mmP7oUDOcNgL1wA/3o/72ydmNhz4LvAxd58EjDazj4UP3wtc3W/FyaClcJDBrgLYAcG8VWb2p7A18aqZdcy8+23gqLC18d1w2+vDbV42s29n7e8CM3vBzNaY2Uf2cMy/A/5PuJ+kBfclWBp+cr88XD/PzJZYcJ+CFWZ2l5klwscWhMd+zcxu79ipBfcceSms6U9ZxzsubNW8aWY9vdEfCaxx9y3h8uKwRjy48nidmUU2c658MKX6uwCRPigxs2VAMcF9Mk4J1zcD57l7nQU3Z/mLmT1CMFHfZHefDmBmZxBMWfxhd280s4Oy9p1y95lmdibwTYI5lDqF0xLs8HC6ZIIrVmvdfYaZFQHPmtnj4WMzCebYf5sgTD5tZs8R3LvgRIJQe9zMzgWeJWiNzHX3t7rUNJFgDv8hwGoz+w8P5nPqsBaYaMFsvzXhz1aY9Xg18BEOzHQd8gGhcJDBqCnrjf4k4L/MbDLB7JP/08zmEkxGNgYY3cPzTwV+Gn6qxt2z58vvmBDxRWBcD889hGAK8Q4fB6aa2fnhciXBnDatBPPavBnW+QuCKVTSwJMdn/LN7H6C+1VkgCUezMPftaZHwzBqMbPN4c/UOQWzu+8wsyuBB8Of+zmC1kSHzQQBI5I3hYMMau7+fNhKGEkwV9VI4ER3T4czahb38DRjz1MWd7QIMvT899HUZZ8GfMXdH9vtAGbzejjGnqZPzremPdbl7r8Dfhce+7Jwuw7FYd0iedOYgwxqZjaR4Daw2wg+tW8Og2E+cES4WT1Bl0yHx4FLLZi3ny5dOLmsYfcWxWPAlRZMx46ZHWPBzYgguAvX+HCs4e+BZwhu8PRRMxthZklgAfAU8Hy4fnwfasLMRoVfhxEMvmff1e8YgknXRPKmloMMRh1jDhB84v6su2fCLprfmVk1wSyfqwDcfZuZPWvBTdr/4O7Xmdl0oNrMWoFFwD/lc2B332Vmb5jZ0e6+luBNeBzBfP9G0OV0brj58wSD4VOAJcBv3L3dzG4EnghrX+Tuv4XOT/y/DsNkM3DaXrwm/2Zm08Lvb3P3NVmPzSGYQVYkb5qVVWQvmdl5BF1XN/eyzTzgWnc/+0DVtYc6jgeucfeL+7MOGXzUchDZS+7+m/DagsFgBPCN/i5CBh+1HEREpBsNSIuISDcKBxER6UbhICIi3SgcRESkG4WDiIh0838BfmgflbBI3uYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = get_mnist_model()\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "model.fit(train_images, train_labels,\n",
    "          epochs=10,\n",
    "          callbacks=[LossHistory()],\n",
    "          validation_data=(val_images, val_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Monitoring and visualization with TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.2906 - accuracy: 0.9128 - val_loss: 0.1532 - val_accuracy: 0.9569\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.1657 - accuracy: 0.9538 - val_loss: 0.1261 - val_accuracy: 0.9655\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 4s 2ms/step - loss: 0.1383 - accuracy: 0.9625 - val_loss: 0.1172 - val_accuracy: 0.9701\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.1238 - accuracy: 0.9679 - val_loss: 0.1129 - val_accuracy: 0.9717\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.1159 - accuracy: 0.9711 - val_loss: 0.1061 - val_accuracy: 0.9750\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.1131 - accuracy: 0.9720 - val_loss: 0.1007 - val_accuracy: 0.9766\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.1038 - accuracy: 0.9753 - val_loss: 0.1100 - val_accuracy: 0.9758\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.1026 - accuracy: 0.9761 - val_loss: 0.1154 - val_accuracy: 0.9765\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.0970 - accuracy: 0.9778 - val_loss: 0.1181 - val_accuracy: 0.9773\n",
      "Epoch 10/10\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.0960 - accuracy: 0.9783 - val_loss: 0.1138 - val_accuracy: 0.9776\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1e0afe13c40>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_mnist_model()\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "tensorboard = keras.callbacks.TensorBoard(\n",
    "    log_dir=\"/full_path_to_your_log_dir\",\n",
    ")\n",
    "model.fit(train_images, train_labels,\n",
    "          epochs=10,\n",
    "          validation_data=(val_images, val_labels),\n",
    "          callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-4d14903542dd0315\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-4d14903542dd0315\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir /full_path_to_your_log_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Writing your own training and evaluation loops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Training versus inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Low-level usage of metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result: 1.00\n"
     ]
    }
   ],
   "source": [
    "metric = keras.metrics.SparseCategoricalAccuracy()\n",
    "targets = [0, 1, 2]\n",
    "predictions = [[1, 0, 0], [0, 1, 0], [0, 0, 1]]\n",
    "metric.update_state(targets, predictions)\n",
    "current_result = metric.result()\n",
    "print(f\"result: {current_result:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of values: 2.00\n"
     ]
    }
   ],
   "source": [
    "values = [0, 1, 2, 3, 4]\n",
    "mean_tracker = keras.metrics.Mean()\n",
    "for value in values:\n",
    "    mean_tracker.update_state(value)\n",
    "print(f\"Mean of values: {mean_tracker.result():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### A complete training and evaluation loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Writing a step-by-step training loop: the training step function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model = get_mnist_model()\n",
    "\n",
    "loss_fn = keras.losses.SparseCategoricalCrossentropy()\n",
    "optimizer = keras.optimizers.RMSprop()\n",
    "metrics = [keras.metrics.SparseCategoricalAccuracy()]\n",
    "loss_tracking_metric = keras.metrics.Mean()\n",
    "\n",
    "def train_step(inputs, targets):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(inputs, training=True)\n",
    "        loss = loss_fn(targets, predictions)\n",
    "    gradients = tape.gradient(loss, model.trainable_weights)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_weights))\n",
    "\n",
    "    logs = {}\n",
    "    for metric in metrics:\n",
    "        metric.update_state(targets, predictions)\n",
    "        logs[metric.name] = metric.result()\n",
    "\n",
    "    loss_tracking_metric.update_state(loss)\n",
    "    logs[\"loss\"] = loss_tracking_metric.result()\n",
    "    return logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Writing a step-by-step training loop: resetting the metrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "def reset_metrics():\n",
    "    for metric in metrics:\n",
    "        metric.reset_state()\n",
    "    loss_tracking_metric.reset_state()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Writing a step-by-step training loop: the loop itself**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results at the end of epoch 0\n",
      "...sparse_categorical_accuracy: 0.9136\n",
      "...loss: 0.2889\n",
      "Results at the end of epoch 1\n",
      "...sparse_categorical_accuracy: 0.9535\n",
      "...loss: 0.1634\n",
      "Results at the end of epoch 2\n",
      "...sparse_categorical_accuracy: 0.9627\n",
      "...loss: 0.1412\n"
     ]
    }
   ],
   "source": [
    "training_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n",
    "training_dataset = training_dataset.batch(32)\n",
    "epochs = 3\n",
    "for epoch in range(epochs):\n",
    "    reset_metrics()\n",
    "    for inputs_batch, targets_batch in training_dataset:\n",
    "        logs = train_step(inputs_batch, targets_batch)\n",
    "    print(f\"Results at the end of epoch {epoch}\")\n",
    "    for key, value in logs.items():\n",
    "        print(f\"...{key}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Writing a step-by-step evaluation loop**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results:\n",
      "...val_sparse_categorical_accuracy: 0.9675\n",
      "...val_loss: 0.1291\n"
     ]
    }
   ],
   "source": [
    "def test_step(inputs, targets):\n",
    "    predictions = model(inputs, training=False)\n",
    "    loss = loss_fn(targets, predictions)\n",
    "\n",
    "    logs = {}\n",
    "    for metric in metrics:\n",
    "        metric.update_state(targets, predictions)\n",
    "        logs[\"val_\" + metric.name] = metric.result()\n",
    "\n",
    "    loss_tracking_metric.update_state(loss)\n",
    "    logs[\"val_loss\"] = loss_tracking_metric.result()\n",
    "    return logs\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_images, val_labels))\n",
    "val_dataset = val_dataset.batch(32)\n",
    "reset_metrics()\n",
    "for inputs_batch, targets_batch in val_dataset:\n",
    "    logs = test_step(inputs_batch, targets_batch)\n",
    "print(\"Evaluation results:\")\n",
    "for key, value in logs.items():\n",
    "    print(f\"...{key}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Make it fast with tf.function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Adding a `tf.function` decorator to our evaluation-step function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results:\n",
      "...val_sparse_categorical_accuracy: 0.9675\n",
      "...val_loss: 0.1291\n"
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "def test_step(inputs, targets):\n",
    "    predictions = model(inputs, training=False)\n",
    "    loss = loss_fn(targets, predictions)\n",
    "\n",
    "    logs = {}\n",
    "    for metric in metrics:\n",
    "        metric.update_state(targets, predictions)\n",
    "        logs[\"val_\" + metric.name] = metric.result()\n",
    "\n",
    "    loss_tracking_metric.update_state(loss)\n",
    "    logs[\"val_loss\"] = loss_tracking_metric.result()\n",
    "    return logs\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_images, val_labels))\n",
    "val_dataset = val_dataset.batch(32)\n",
    "reset_metrics()\n",
    "for inputs_batch, targets_batch in val_dataset:\n",
    "    logs = test_step(inputs_batch, targets_batch)\n",
    "print(\"Evaluation results:\")\n",
    "for key, value in logs.items():\n",
    "    print(f\"...{key}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Leveraging fit() with a custom training loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Implementing a custom training step to use with `fit()`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "loss_fn = keras.losses.SparseCategoricalCrossentropy()\n",
    "loss_tracker = keras.metrics.Mean(name=\"loss\")\n",
    "\n",
    "class CustomModel(keras.Model):\n",
    "    def train_step(self, data):\n",
    "        inputs, targets = data\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self(inputs, training=True)\n",
    "            loss = loss_fn(targets, predictions)\n",
    "        gradients = tape.gradient(loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.trainable_weights))\n",
    "\n",
    "        loss_tracker.update_state(loss)\n",
    "        return {\"loss\": loss_tracker.result()}\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [loss_tracker]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 0.2947\n",
      "Epoch 2/3\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 0.1654\n",
      "Epoch 3/3\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 0.1400\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1e0bf4ec0a0>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(28 * 28,))\n",
    "features = layers.Dense(512, activation=\"relu\")(inputs)\n",
    "features = layers.Dropout(0.5)(features)\n",
    "outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
    "model = CustomModel(inputs, outputs)\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.RMSprop())\n",
    "model.fit(train_images, train_labels, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "class CustomModel(keras.Model):\n",
    "    def train_step(self, data):\n",
    "        inputs, targets = data\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self(inputs, training=True)\n",
    "            loss = self.compiled_loss(targets, predictions)\n",
    "        gradients = tape.gradient(loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.trainable_weights))\n",
    "        self.compiled_metrics.update_state(targets, predictions)\n",
    "        return {m.name: m.result() for m in self.metrics}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1563/1563 [==============================] - 4s 2ms/step - loss: 0.2942 - sparse_categorical_accuracy: 0.9126\n",
      "Epoch 2/3\n",
      "1563/1563 [==============================] - 4s 2ms/step - loss: 0.1657 - sparse_categorical_accuracy: 0.9548\n",
      "Epoch 3/3\n",
      "1563/1563 [==============================] - 4s 2ms/step - loss: 0.1393 - sparse_categorical_accuracy: 0.9628\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1e0c8d235b0>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(28 * 28,))\n",
    "features = layers.Dense(512, activation=\"relu\")(inputs)\n",
    "features = layers.Dropout(0.5)(features)\n",
    "outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
    "model = CustomModel(inputs, outputs)\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.RMSprop(),\n",
    "              loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "              metrics=[keras.metrics.SparseCategoricalAccuracy()])\n",
    "model.fit(train_images, train_labels, epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Summary"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "chapter07_working-with-keras.i",
   "private_outputs": false,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
